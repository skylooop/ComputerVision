{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeXssqQTsZfv"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import spacy\r\n",
        "import random\r\n",
        "from torchtext.datasets import Multi30k\r\n",
        "from torchtext.data import Field, BucketIterator\r\n",
        "from torch.utils.tensorboard import SummaryWriter\r\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwFPwrTrs7E9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b82eda8-d743-4157-907c-8be3319df4bc"
      },
      "source": [
        "!python -m spacy download de_core_news_sm\r\n",
        "import en_core_web_sm\r\n",
        "import de_core_news_sm\r\n",
        "\r\n",
        "spacy_en = en_core_web_sm.load()\r\n",
        "spacy_ger = de_core_news_sm.load()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (53.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp37-none-any.whl size=14907057 sha256=ae3722f5eb0fd251c4883a856f9914677b288bf29db1b2bfb43656da4e2bae33\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cgvmeutg/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN115rI-t0i7"
      },
      "source": [
        "def tokenizer_ger(text):\r\n",
        "  return [tok.text for tok in spacy_ger.tokenizer(text)]\r\n",
        "\r\n",
        "def tokenizer_en(text):\r\n",
        "  return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxsO1xGQyELF"
      },
      "source": [
        "german = Field(tokenize=tokenizer_ger, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\r\n",
        "english = Field(tokenize=tokenizer_en, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhdodpp7zLNs",
        "outputId": "61a99af4-7a80-40ca-fd38-576129950373"
      },
      "source": [
        "train, val, test = Multi30k.splits(exts = ('.de', '.en'), fields=(german, english))\r\n",
        "german.build_vocab(train, max_size = 10000, min_freq = 2)\r\n",
        "english.build_vocab(train, max_size = 10000, min_freq = 2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 970kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 273kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 268kB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7YyKV743QSx"
      },
      "source": [
        "device = torch.device(\"cuda\")\r\n",
        "train_gen, val_gen, test_gen = BucketIterator.splits((train, val, test), sort_within_batch = True, sort_key = lambda x: len(x.src), batch_size=128,device=device)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxwDl4X4z8DE"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "  def __init__(self, input_size, embd_dim, hid_size, num_layers, rate):\r\n",
        "    super().__init__()\r\n",
        "    self.hid_size = hid_size\r\n",
        "    self.num_layers = num_layers\r\n",
        "    self.drop = nn.Dropout(rate)\r\n",
        "    self.emb = nn.Embedding(input_size, embd_dim)\r\n",
        "    self.rnn = nn.LSTM(embd_dim, hid_size, num_layers, dropout = rate)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    #sent len x batch\r\n",
        "    emb = self.drop(self.emb(x)) #sent len x batch x emb_sizetown \r\n",
        "    out, (hidden, cell) = self.rnn(emb)\r\n",
        "    return hidden, cell\r\n",
        "\r\n",
        "class Decoder(nn.Module):\r\n",
        "  def __init__(self, input_size, emb_size, hid_size, out, num_layers, dropout):\r\n",
        "    super().__init__()\r\n",
        "    self.hidden_size = hid_size\r\n",
        "    self.num_layers = num_layers\r\n",
        "    self.dropout = nn.Dropout(dropout)\r\n",
        "    self.embedding = nn.Embedding(input_size, emb_size)\r\n",
        "    self.rnn = nn.LSTM(emb_size, hid_size, num_layers, dropout = dropout)\r\n",
        "    self.fc = nn.Linear(hid_size, out)\r\n",
        "\r\n",
        "\r\n",
        "  def forward(self, x,hidden, cell):\r\n",
        "    #shape of x: (N) we want (1,N)\r\n",
        "    x = x.unsqueeze(0)\r\n",
        "    embed = self.dropout(self.embedding(x)) #(1, N, embed_size)\r\n",
        "    out, (hidden, cell) = self.rnn(embed, (hidden, cell))\r\n",
        "    preds = self.fc(out) #(1, N, len of vocab)\r\n",
        "    preds = preds.squeeze(0)\r\n",
        "    return preds, hidden, cell\r\n",
        "\r\n",
        "class seq2seq(nn.Module): # combine\r\n",
        "  def __init__(self, encoder, decoder):\r\n",
        "    super().__init__()\r\n",
        "    self.enc = encoder\r\n",
        "    self.dec = decoder\r\n",
        "\r\n",
        "  def forward(self, source, target, teacher = 0.5):\r\n",
        "    batch = source.shape[1]\r\n",
        "    target_len = target.shape[0]\r\n",
        "    target_vocab_size = len(english.vocab)\r\n",
        "    outputs = torch.zeros(target_len, batch, target_vocab_size)\r\n",
        "\r\n",
        "    hidden, cell = self.enc(source)\r\n",
        "    x = target[0] #start\r\n",
        "    for t in range(1, target_len):\r\n",
        "      out, hidden, cell = self.dec(x, hidden, cell)\r\n",
        "      outputs[t] = out\r\n",
        "      best_guess = out.argmax(1)\r\n",
        "      x = target[t] if random.random() < teacher else best_guess\r\n",
        "    return outputs"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLIv3I3qwxmY"
      },
      "source": [
        "epochs = 20\r\n",
        "lr = 0.001\r\n",
        "batch_size = 64\r\n",
        "load_model = False\r\n",
        "device = torch.device(\"cuda\")\r\n",
        "input_size_enc = len(german.vocab)\r\n",
        "input_size_dec = len(english.vocab)\r\n",
        "out_size = len(english.vocab)\r\n",
        "encoder_emb_size = 300\r\n",
        "dec_emb_size = 300\r\n",
        "hidden_size = 1024\r\n",
        "num_layers = 2\r\n",
        "enc_drop = 0.5\r\n",
        "dec_drop = 0.5"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLSkvQQc_e4d"
      },
      "source": [
        "encoder_net = Encoder(input_size_enc, encoder_emb_size, hidden_size, num_layers, enc_drop).to(device)\r\n",
        "decoder_net = Decoder(input_size_dec, dec_emb_size, hidden_size, out=out_size, num_layers = num_layers, dropout = dec_drop).to(device)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sy3RQyL2_sn8",
        "outputId": "568b138b-328e-4742-d2f2-6cea1b1ca53c"
      },
      "source": [
        "pad_idx = english.vocab.stoi['<pad>']\r\n",
        "crit = nn.CrossEntropyLoss(ignore_index=pad_idx)\r\n",
        "model = seq2seq(encoder_net, decoder_net).to(device)\r\n",
        "optimizer = optim.Adam(model.parameters())\r\n",
        "for epoch in range(epochs):\r\n",
        "  print(f\"Epoch {epoch}/{epochs}\")\r\n",
        "\r\n",
        "  for batch_idx, batch in enumerate(train_gen):\r\n",
        "    inp_data = batch.src.to(device)\r\n",
        "    target = batch.trg.to(device)\r\n",
        "    out = model(inp_data, target)\r\n",
        "    out = out[1:].view(-1, out.shape[-1]).to(device)\r\n",
        "    target = target[1:].view(-1)\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "    loss = crit(out, target)\r\n",
        "    loss.backward()\r\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\r\n",
        "    optimizer.step()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "ChsXgsxKGK6y",
        "outputId": "afb41369-ba49-4221-b0d4-5879d6e039a4"
      },
      "source": [
        "sentence = \"ein boot mir mehreren\"\r\n",
        "model(sentence, \"one boat with several\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-873d899c0c08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ein boot mir mehreren\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"one boat with several\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-6ff106271918>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, source, target, teacher)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mtarget_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mtarget_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menglish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBbE_vhNV9dP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}